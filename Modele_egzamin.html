<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Michał Koziński">

<title>SMLiN_egzamin</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="Modele_egzamin_files/libs/clipboard/clipboard.min.js"></script>
<script src="Modele_egzamin_files/libs/quarto-html/quarto.js"></script>
<script src="Modele_egzamin_files/libs/quarto-html/popper.min.js"></script>
<script src="Modele_egzamin_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="Modele_egzamin_files/libs/quarto-html/anchor.min.js"></script>
<link href="Modele_egzamin_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="Modele_egzamin_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="Modele_egzamin_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="Modele_egzamin_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="Modele_egzamin_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#zagadnienia-do-przygotowania-na-egzamin-ustny-z-statystycznych-modeli-liniowych-i-nieliniowych" id="toc-zagadnienia-do-przygotowania-na-egzamin-ustny-z-statystycznych-modeli-liniowych-i-nieliniowych" class="nav-link active" data-scroll-target="#zagadnienia-do-przygotowania-na-egzamin-ustny-z-statystycznych-modeli-liniowych-i-nieliniowych">Zagadnienia do przygotowania na egzamin ustny z Statystycznych Modeli Liniowych i Nieliniowych</a>
  <ul class="collapse">
  <li><a href="#podaj-postać-ogólną-modelu-regresji-wielorakiej." id="toc-podaj-postać-ogólną-modelu-regresji-wielorakiej." class="nav-link" data-scroll-target="#podaj-postać-ogólną-modelu-regresji-wielorakiej.">1. Podaj postać ogólną modelu regresji wielorakiej.</a></li>
  <li><a href="#przedstaw-model-liniowy-w-zapisie-macierzowym." id="toc-przedstaw-model-liniowy-w-zapisie-macierzowym." class="nav-link" data-scroll-target="#przedstaw-model-liniowy-w-zapisie-macierzowym.">2. Przedstaw model liniowy w zapisie macierzowym.</a></li>
  <li><a href="#wymień-założenia-jakie-muszą-być-spełnione-aby-parametry-modelu-otrzymane-metodą-najmniejszych-kwadratów-były-blue." id="toc-wymień-założenia-jakie-muszą-być-spełnione-aby-parametry-modelu-otrzymane-metodą-najmniejszych-kwadratów-były-blue." class="nav-link" data-scroll-target="#wymień-założenia-jakie-muszą-być-spełnione-aby-parametry-modelu-otrzymane-metodą-najmniejszych-kwadratów-były-blue.">3. Wymień założenia jakie muszą być spełnione, aby parametry modelu otrzymane metodą najmniejszych kwadratów były BLUE.</a></li>
  <li><a href="#na-czym-polega-metoda-najmniejszych-kwadratów" id="toc-na-czym-polega-metoda-najmniejszych-kwadratów" class="nav-link" data-scroll-target="#na-czym-polega-metoda-najmniejszych-kwadratów">4. Na czym polega metoda najmniejszych kwadratów?</a></li>
  <li><a href="#podaj-wzór-na-wektor-parametrów-hatbeta." id="toc-podaj-wzór-na-wektor-parametrów-hatbeta." class="nav-link" data-scroll-target="#podaj-wzór-na-wektor-parametrów-hatbeta.">5. Podaj wzór na wektor parametrów <span class="math inline">\(\hat\beta\)</span>“.</a></li>
  <li><a href="#podaj-twierdzenie-z-dowodem-mówiące-o-postaci-macierzy-kowariancji-parametrów-modelu-liniowego." id="toc-podaj-twierdzenie-z-dowodem-mówiące-o-postaci-macierzy-kowariancji-parametrów-modelu-liniowego." class="nav-link" data-scroll-target="#podaj-twierdzenie-z-dowodem-mówiące-o-postaci-macierzy-kowariancji-parametrów-modelu-liniowego.">6. Podaj twierdzenie z dowodem mówiące o postaci macierzy kowariancji parametrów modelu liniowego.</a></li>
  <li><a href="#podaj-wzór-estymatora-wariancji-sigma2-dla-regresji-liniowej-i-podaj-jego-własności." id="toc-podaj-wzór-estymatora-wariancji-sigma2-dla-regresji-liniowej-i-podaj-jego-własności." class="nav-link" data-scroll-target="#podaj-wzór-estymatora-wariancji-sigma2-dla-regresji-liniowej-i-podaj-jego-własności.">7. Podaj wzór estymatora wariancji <span class="math inline">\(\sigma^2\)</span> dla regresji liniowej i podaj jego własności.</a></li>
  <li><a href="#do-czego-służy-test-f-w-modelach-liniowych" id="toc-do-czego-służy-test-f-w-modelach-liniowych" class="nav-link" data-scroll-target="#do-czego-służy-test-f-w-modelach-liniowych">8. Do czego służy test F w modelach liniowych?</a></li>
  <li><a href="#czym-są-modele-zagnieżdżone" id="toc-czym-są-modele-zagnieżdżone" class="nav-link" data-scroll-target="#czym-są-modele-zagnieżdżone">9. Czym są modele zagnieżdżone?</a></li>
  <li><a href="#jakie-są-obciążenie-i-wariancja-parametrów-modeli-niedouczonych-i-przeuczonych" id="toc-jakie-są-obciążenie-i-wariancja-parametrów-modeli-niedouczonych-i-przeuczonych" class="nav-link" data-scroll-target="#jakie-są-obciążenie-i-wariancja-parametrów-modeli-niedouczonych-i-przeuczonych">10. Jakie są obciążenie i wariancja parametrów modeli niedouczonych i przeuczonych?</a></li>
  <li><a href="#jak-testujemy-poszczególne-efekty-w-modelu-regresji-wielorakiej" id="toc-jak-testujemy-poszczególne-efekty-w-modelu-regresji-wielorakiej" class="nav-link" data-scroll-target="#jak-testujemy-poszczególne-efekty-w-modelu-regresji-wielorakiej">11. Jak testujemy poszczególne efekty w modelu regresji wielorakiej?</a></li>
  <li><a href="#wymień-znane-ci-miary-dopasowania-modelu-regresji-podaj-wzory-3-z-nich." id="toc-wymień-znane-ci-miary-dopasowania-modelu-regresji-podaj-wzory-3-z-nich." class="nav-link" data-scroll-target="#wymień-znane-ci-miary-dopasowania-modelu-regresji-podaj-wzory-3-z-nich.">12. Wymień znane Ci miary dopasowania modelu regresji (podaj wzory 3 z nich).</a></li>
  <li><a href="#podaj-przyczyny-i-skutki-niespełnienia-założenia-o-jednorodności-wariancji-błędów-w-modelach-regresji." id="toc-podaj-przyczyny-i-skutki-niespełnienia-założenia-o-jednorodności-wariancji-błędów-w-modelach-regresji." class="nav-link" data-scroll-target="#podaj-przyczyny-i-skutki-niespełnienia-założenia-o-jednorodności-wariancji-błędów-w-modelach-regresji.">13. Podaj przyczyny i skutki niespełnienia założenia o jednorodności wariancji błędów w modelach regresji.</a></li>
  <li><a href="#podaj-przyczyny-i-skutki-niespełnienia-założenia-o-liniowym-charakterze-zależności-w-modelach-regresji." id="toc-podaj-przyczyny-i-skutki-niespełnienia-założenia-o-liniowym-charakterze-zależności-w-modelach-regresji." class="nav-link" data-scroll-target="#podaj-przyczyny-i-skutki-niespełnienia-założenia-o-liniowym-charakterze-zależności-w-modelach-regresji.">14. Podaj przyczyny i skutki niespełnienia założenia o liniowym charakterze zależności w modelach regresji.</a></li>
  <li><a href="#podaj-przyczyny-i-skutki-endogeniczności-w-modelach-regresji." id="toc-podaj-przyczyny-i-skutki-endogeniczności-w-modelach-regresji." class="nav-link" data-scroll-target="#podaj-przyczyny-i-skutki-endogeniczności-w-modelach-regresji.">15. Podaj przyczyny i skutki endogeniczności w modelach regresji.</a></li>
  <li><a href="#podaj-przyczyny-i-skutki-niespełnienia-założenia-o-braku-kowariancji-pomiędzy-błędami-w-modelach-regresji." id="toc-podaj-przyczyny-i-skutki-niespełnienia-założenia-o-braku-kowariancji-pomiędzy-błędami-w-modelach-regresji." class="nav-link" data-scroll-target="#podaj-przyczyny-i-skutki-niespełnienia-założenia-o-braku-kowariancji-pomiędzy-błędami-w-modelach-regresji.">16. Podaj przyczyny i skutki niespełnienia założenia o braku kowariancji pomiędzy błędami w modelach regresji.</a></li>
  <li><a href="#czym-jest-heterogeniczność-próbkowa-i-modelowa" id="toc-czym-jest-heterogeniczność-próbkowa-i-modelowa" class="nav-link" data-scroll-target="#czym-jest-heterogeniczność-próbkowa-i-modelowa">17. Czym jest heterogeniczność próbkowa i modelowa?</a></li>
  <li><a href="#podaj-przyczyny-i-skutki-nadmiarowości-w-modelach-regresji." id="toc-podaj-przyczyny-i-skutki-nadmiarowości-w-modelach-regresji." class="nav-link" data-scroll-target="#podaj-przyczyny-i-skutki-nadmiarowości-w-modelach-regresji.">18. Podaj przyczyny i skutki nadmiarowości w modelach regresji.</a></li>
  <li><a href="#jakie-są-konsekwencje-braku-normalności-wektora-błędów" id="toc-jakie-są-konsekwencje-braku-normalności-wektora-błędów" class="nav-link" data-scroll-target="#jakie-są-konsekwencje-braku-normalności-wektora-błędów">19. Jakie są konsekwencje braku normalności wektora błędów?</a></li>
  <li><a href="#jakie-znasz-wykresy-diagnostyczne-do-testowania-założeń-modelu-linowego" id="toc-jakie-znasz-wykresy-diagnostyczne-do-testowania-założeń-modelu-linowego" class="nav-link" data-scroll-target="#jakie-znasz-wykresy-diagnostyczne-do-testowania-założeń-modelu-linowego">20. Jakie znasz wykresy diagnostyczne do testowania założeń modelu linowego?</a></li>
  <li><a href="#wymień-testy-do-weryfikacji-hipotezy-o-równości-wariancji-wektora-błędów." id="toc-wymień-testy-do-weryfikacji-hipotezy-o-równości-wariancji-wektora-błędów." class="nav-link" data-scroll-target="#wymień-testy-do-weryfikacji-hipotezy-o-równości-wariancji-wektora-błędów.">21. Wymień testy do weryfikacji hipotezy o równości wariancji wektora błędów.</a></li>
  <li><a href="#wymień-testy-do-weryfikacji-hipotezy-o-braku-seryjnej-korelacji-błędów-modelu-liniowego." id="toc-wymień-testy-do-weryfikacji-hipotezy-o-braku-seryjnej-korelacji-błędów-modelu-liniowego." class="nav-link" data-scroll-target="#wymień-testy-do-weryfikacji-hipotezy-o-braku-seryjnej-korelacji-błędów-modelu-liniowego.">22. Wymień testy do weryfikacji hipotezy o braku seryjnej korelacji błędów modelu liniowego.</a></li>
  <li><a href="#wymień-testy-do-weryfikacji-hipotezy-o-liniowej-postaci-zależności-pomiędzy-zmienną-objaśnianą-i-objaśniającymi." id="toc-wymień-testy-do-weryfikacji-hipotezy-o-liniowej-postaci-zależności-pomiędzy-zmienną-objaśnianą-i-objaśniającymi." class="nav-link" data-scroll-target="#wymień-testy-do-weryfikacji-hipotezy-o-liniowej-postaci-zależności-pomiędzy-zmienną-objaśnianą-i-objaśniającymi.">23. Wymień testy do weryfikacji hipotezy o liniowej postaci zależności pomiędzy zmienną objaśnianą i objaśniającymi.</a></li>
  <li><a href="#wypowiedz-twierdzenie-mówiące-o-własnościach-macierzy-h-modelu-liniowego." id="toc-wypowiedz-twierdzenie-mówiące-o-własnościach-macierzy-h-modelu-liniowego." class="nav-link" data-scroll-target="#wypowiedz-twierdzenie-mówiące-o-własnościach-macierzy-h-modelu-liniowego.">24. Wypowiedz twierdzenie mówiące o własnościach macierzy H modelu liniowego.</a></li>
  <li><a href="#czym-są-obserwacje-odstające-dobrej-i-złej-dźwigni" id="toc-czym-są-obserwacje-odstające-dobrej-i-złej-dźwigni" class="nav-link" data-scroll-target="#czym-są-obserwacje-odstające-dobrej-i-złej-dźwigni">25. Czym są obserwacje odstające, dobrej i złej dźwigni?</a></li>
  <li><a href="#podaj-wzór-odległości-cooka-i-powiedz-do-czego-ona-służy." id="toc-podaj-wzór-odległości-cooka-i-powiedz-do-czego-ona-służy." class="nav-link" data-scroll-target="#podaj-wzór-odległości-cooka-i-powiedz-do-czego-ona-służy.">26. Podaj wzór odległości Cooka i powiedz do czego ona służy.</a></li>
  <li><a href="#podaj-wzór-reszt-standaryzowanych-i-studentyzowanych." id="toc-podaj-wzór-reszt-standaryzowanych-i-studentyzowanych." class="nav-link" data-scroll-target="#podaj-wzór-reszt-standaryzowanych-i-studentyzowanych.">27. Podaj wzór reszt standaryzowanych i studentyzowanych.</a></li>
  <li><a href="#czym-są-miary-dffit-dfbeta-covratio" id="toc-czym-są-miary-dffit-dfbeta-covratio" class="nav-link" data-scroll-target="#czym-są-miary-dffit-dfbeta-covratio">28. Czym są miary DFFIT, DFBETA, COVRATIO?</a></li>
  <li><a href="#opisz-metodę-największej-wiarogodności-wiarygodności-w-kontekście-modeli-liniowych." id="toc-opisz-metodę-największej-wiarogodności-wiarygodności-w-kontekście-modeli-liniowych." class="nav-link" data-scroll-target="#opisz-metodę-największej-wiarogodności-wiarygodności-w-kontekście-modeli-liniowych.">29. Opisz metodę największej wiarogodności (wiarygodności) w kontekście modeli liniowych.</a></li>
  <li><a href="#podaj-własności-estymatora-parametrów-modelu-otrzymanego-metodą-największej-wiarogodności." id="toc-podaj-własności-estymatora-parametrów-modelu-otrzymanego-metodą-największej-wiarogodności." class="nav-link" data-scroll-target="#podaj-własności-estymatora-parametrów-modelu-otrzymanego-metodą-największej-wiarogodności.">30. Podaj własności estymatora parametrów modelu otrzymanego metodą największej wiarogodności.</a></li>
  <li><a href="#czym-jest-przedział-ufności-dla-regresji-i-predykcji" id="toc-czym-jest-przedział-ufności-dla-regresji-i-predykcji" class="nav-link" data-scroll-target="#czym-jest-przedział-ufności-dla-regresji-i-predykcji">31. Czym jest przedział ufności dla regresji i predykcji?</a></li>
  <li><a href="#jakie-są-powody-transformacji-zmiennych-objaśniających-i-objaśnianych-w-modelach-liniowych" id="toc-jakie-są-powody-transformacji-zmiennych-objaśniających-i-objaśnianych-w-modelach-liniowych" class="nav-link" data-scroll-target="#jakie-są-powody-transformacji-zmiennych-objaśniających-i-objaśnianych-w-modelach-liniowych">32. Jakie są powody transformacji zmiennych objaśniających i objaśnianych w modelach liniowych?</a></li>
  <li><a href="#jak-interpretować-model-którego-zmienne-są-logarytmowane" id="toc-jak-interpretować-model-którego-zmienne-są-logarytmowane" class="nav-link" data-scroll-target="#jak-interpretować-model-którego-zmienne-są-logarytmowane">33. Jak interpretować model, którego zmienne są logarytmowane?</a></li>
  <li><a href="#czym-jest-przekształcenie-potęgowe-i-do-czego-służy" id="toc-czym-jest-przekształcenie-potęgowe-i-do-czego-służy" class="nav-link" data-scroll-target="#czym-jest-przekształcenie-potęgowe-i-do-czego-służy">34. Czym jest przekształcenie potęgowe i do czego służy?</a></li>
  <li><a href="#na-czym-polega-transformacja-box-cox-i-czym-się-różni-od-transformacji-yeo-johnsona" id="toc-na-czym-polega-transformacja-box-cox-i-czym-się-różni-od-transformacji-yeo-johnsona" class="nav-link" data-scroll-target="#na-czym-polega-transformacja-box-cox-i-czym-się-różni-od-transformacji-yeo-johnsona">35. Na czym polega transformacja Box-Cox i czym się różni od transformacji Yeo-Johnsona?</a></li>
  <li><a href="#opisz-zasadę-działania-ważonej-metody-najmniejszych-kwadratów." id="toc-opisz-zasadę-działania-ważonej-metody-najmniejszych-kwadratów." class="nav-link" data-scroll-target="#opisz-zasadę-działania-ważonej-metody-najmniejszych-kwadratów.">36. Opisz zasadę działania ważonej metody najmniejszych kwadratów.</a></li>
  <li><a href="#na-czym-polega-metoda-fwls-fgls" id="toc-na-czym-polega-metoda-fwls-fgls" class="nav-link" data-scroll-target="#na-czym-polega-metoda-fwls-fgls">37. Na czym polega metoda FWLS (FGLS)?</a></li>
  <li><a href="#czym-są-estymatory-whitea" id="toc-czym-są-estymatory-whitea" class="nav-link" data-scroll-target="#czym-są-estymatory-whitea">38. Czym są estymatory White’a?</a></li>
  <li><a href="#czym-jest-i-do-czego-służy-ancova" id="toc-czym-jest-i-do-czego-służy-ancova" class="nav-link" data-scroll-target="#czym-jest-i-do-czego-służy-ancova">39. Czym jest i do czego służy ANCOVA?</a></li>
  <li><a href="#czym-jest-regresja-wielomianowa-i-jak-można-ją-wykorzystać-w-modelowaniu-zależności-pomiędzy-cechami" id="toc-czym-jest-regresja-wielomianowa-i-jak-można-ją-wykorzystać-w-modelowaniu-zależności-pomiędzy-cechami" class="nav-link" data-scroll-target="#czym-jest-regresja-wielomianowa-i-jak-można-ją-wykorzystać-w-modelowaniu-zależności-pomiędzy-cechami">40. Czym jest regresja wielomianowa i jak można ją wykorzystać w modelowaniu zależności pomiędzy cechami?</a></li>
  <li><a href="#przeprowadź-dyskusję-na-temat-naruszeń-założeń-modelu-anova." id="toc-przeprowadź-dyskusję-na-temat-naruszeń-założeń-modelu-anova." class="nav-link" data-scroll-target="#przeprowadź-dyskusję-na-temat-naruszeń-założeń-modelu-anova.">41. Przeprowadź dyskusję na temat naruszeń założeń modelu ANOVA.</a></li>
  <li><a href="#wymień-znane-ci-testy-post-hoc-oraz-określ-podobieństwa-i-różnice-pomiędzy-nimi." id="toc-wymień-znane-ci-testy-post-hoc-oraz-określ-podobieństwa-i-różnice-pomiędzy-nimi." class="nav-link" data-scroll-target="#wymień-znane-ci-testy-post-hoc-oraz-określ-podobieństwa-i-różnice-pomiędzy-nimi.">42. Wymień znane Ci testy post-hoc oraz określ podobieństwa i różnice pomiędzy nimi.</a></li>
  <li><a href="#czym-są-porównania-zaplanowane" id="toc-czym-są-porównania-zaplanowane" class="nav-link" data-scroll-target="#czym-są-porównania-zaplanowane">43. Czym są porównania zaplanowane?</a></li>
  <li><a href="#podaj-przykłady-trzech-predefiniowanych-kontrastów." id="toc-podaj-przykłady-trzech-predefiniowanych-kontrastów." class="nav-link" data-scroll-target="#podaj-przykłady-trzech-predefiniowanych-kontrastów.">44. Podaj przykłady trzech predefiniowanych kontrastów.</a></li>
  <li><a href="#czym-są-kontrasty-ortogonalne" id="toc-czym-są-kontrasty-ortogonalne" class="nav-link" data-scroll-target="#czym-są-kontrasty-ortogonalne">45. Czym są kontrasty ortogonalne?</a></li>
  <li><a href="#na-czym-polegają-różnice-w-typach-testów-i-ii-iii-anova" id="toc-na-czym-polegają-różnice-w-typach-testów-i-ii-iii-anova" class="nav-link" data-scroll-target="#na-czym-polegają-różnice-w-typach-testów-i-ii-iii-anova">46. Na czym polegają różnice w typach testów (I, II, III) ANOVA?</a>
  <ul class="collapse">
  <li><a href="#test-typu-i" id="toc-test-typu-i" class="nav-link" data-scroll-target="#test-typu-i"><strong>Test typu I</strong></a></li>
  <li><a href="#test-typu-ii" id="toc-test-typu-ii" class="nav-link" data-scroll-target="#test-typu-ii"><strong>Test typu II</strong></a></li>
  <li><a href="#test-typu-iii" id="toc-test-typu-iii" class="nav-link" data-scroll-target="#test-typu-iii"><strong>Test typu III</strong></a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">SMLiN_egzamin</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Michał Koziński </p>
          </div>
  </div>
    
  
    
  </div>
  

</header>

<section id="zagadnienia-do-przygotowania-na-egzamin-ustny-z-statystycznych-modeli-liniowych-i-nieliniowych" class="level1">
<h1>Zagadnienia do przygotowania na egzamin ustny z Statystycznych Modeli Liniowych i Nieliniowych</h1>
<hr>
<!-- wykład 1 -->
<section id="podaj-postać-ogólną-modelu-regresji-wielorakiej." class="level2">
<h2 class="anchored" data-anchor-id="podaj-postać-ogólną-modelu-regresji-wielorakiej.">1. Podaj postać ogólną modelu regresji wielorakiej.</h2>
<p>Przez model liniowy (w sensie ścisłym) będziemy rozumieć wszystkie modele postaci <span class="math display">\[y = E(Y|X_1 = x_1 , ... , X_p = x_p) \stackrel{\text{def}}{=} \beta_0 + \beta_1 x_1 + ... + \beta_px_p + \varepsilon,\]</span> gdzie <span class="math inline">\(Y\)</span> jest zmienną objaśnianą, <span class="math inline">\(X_1,...,X_p\)</span> są zmiennymi objaśniającymi, a <span class="math inline">\(x_1,...,x_p\)</span> ich realizacjami, <span class="math inline">\(\varepsilon\)</span> jest błędem modelu, natomiast <span class="math inline">\(\beta_0,...,\beta_p\)</span> nieznanymi parametrami równania (parametrami strukturalnymi równania).</p>
<p>Przez modele liniowe (w szerszym sensie - liniowe względem parametrów, zwane także linearyzowalnymi) rozumie się takie modele, które zawierają zmienne objaśniające poddane transformacji (np. <span class="math inline">\(X_i^3\)</span>, <span class="math inline">\(log(X_i)\)</span> lub interakcje zmiennych objaśniających (np. <span class="math inline">\(X_2X_3\)</span>).</p>
<p><br></p>
</section>
<section id="przedstaw-model-liniowy-w-zapisie-macierzowym." class="level2">
<h2 class="anchored" data-anchor-id="przedstaw-model-liniowy-w-zapisie-macierzowym.">2. Przedstaw model liniowy w zapisie macierzowym.</h2>
<p>Zapis macierzowy modelu liniowego przyjmuje postać <span class="math display">\[\textbf{Y}=\textbf{X}\beta + \varepsilon,\]</span> gdzie</p>
<p><span class="math display">\[\textbf{Y} =\begin{pmatrix} y_1 \\ y_2 \\ \vdots \\ y_n \end{pmatrix},
\textbf{X} =\begin{pmatrix} 1 &amp; x_{11} &amp; \cdots &amp; x_{1p} \\
1 &amp; x_{21} &amp; \cdots &amp; x_{2p} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
1 &amp; x_{n1} &amp; \cdots &amp; x_{np} \end{pmatrix},
\beta =\begin{pmatrix} \beta_0 \\ \beta_1 \\ \vdots \\ \beta_p \end{pmatrix},
\varepsilon =\begin{pmatrix} \varepsilon_1 \\ \varepsilon_2 \\ \vdots \\ \varepsilon_n \end{pmatrix} \]</span></p>
<p>Dodatkowo o błędzie modelu przyjmuje się, że <span class="math inline">\(E(\varepsilon|\textbf{X}) = 0\)</span> i <span class="math inline">\(Cov(\varepsilon|\textbf{X}) = \sigma^2I\)</span>.</p>
<p><br></p>
</section>
<section id="wymień-założenia-jakie-muszą-być-spełnione-aby-parametry-modelu-otrzymane-metodą-najmniejszych-kwadratów-były-blue." class="level2">
<h2 class="anchored" data-anchor-id="wymień-założenia-jakie-muszą-być-spełnione-aby-parametry-modelu-otrzymane-metodą-najmniejszych-kwadratów-były-blue.">3. Wymień założenia jakie muszą być spełnione, aby parametry modelu otrzymane metodą najmniejszych kwadratów były BLUE.</h2>
<p>Na to aby estymatory parametrów strukturalnych modelu otrzymane metodą najmniejszych kwadratów(OLS) były BLUE(Best Linear Unbiased Estimators) muszą być spełnione następujące warunki (tw. Gaussa-Markova):</p>
<ol type="1">
<li><p>Charakter zależności pomiędzy zmiennymi objaśniającymi, a objaśnianą powinien być liniowy.</p></li>
<li><p>Liczba obserwacji w próbie musi być większa (najlepiej znacznie większa) od liczby szacowanych w modelu parametrów.</p></li>
<li><p>Zmienne objaśniające nie powinny wykazywać współliniowości (redundancji - nadmiarowości).</p></li>
<li><p>Składniki losowe (błędy) powinny być nieskorelowane o stałej wariancji i mieć średnią równą zero, co zapisujemy <span class="math inline">\(E(\varepsilon|\textbf{X}) = 0\)</span> i <span class="math inline">\(Cov(\varepsilon|\textbf{X}) = \sigma^2I\)</span>.</p></li>
</ol>
<p><br></p>
</section>
<section id="na-czym-polega-metoda-najmniejszych-kwadratów" class="level2">
<h2 class="anchored" data-anchor-id="na-czym-polega-metoda-najmniejszych-kwadratów">4. Na czym polega metoda najmniejszych kwadratów?</h2>
<p>Model otrzymany tą metodą oznaczamy jako <span class="math inline">\(\hat y_{\text{OLS}} = X\hat\beta\;\)</span>, gdzie <br> <span class="math inline">\(\hat y_{\text{OLS}}\)</span> jest wartością teoretyczną oszacowaną na podstawie modelu, <br> <span class="math inline">\(\hat\beta\)</span> jest estymatorem wektora parametrów <span class="math inline">\(\beta\)</span>.</p>
<p>Procedura estymacji parametrów najszerzej może być opisana jako minimalizacja następującej funkcji celu (straty) <span class="math display">\[\sum\limits^n_{i=1}M(e_i)\stackrel{\text{def}}{=}\sum\limits^n_{i=1}M(y_i - \hat y_i)\]</span> gdzie <br> M przyjmuje się najczęściej jako <span class="math inline">\(M(x) = |x|\)</span> lub (jak w przypadku OLS) <span class="math inline">\(M(x)=x^2\)</span>.</p>
<p><br></p>
</section>
<section id="podaj-wzór-na-wektor-parametrów-hatbeta." class="level2">
<h2 class="anchored" data-anchor-id="podaj-wzór-na-wektor-parametrów-hatbeta.">5. Podaj wzór na wektor parametrów <span class="math inline">\(\hat\beta\)</span>“.</h2>
<p>Estymator <span class="math inline">\(\hat\beta = (X'X)^{-1}X'y\)</span> &nbsp;&nbsp; jest nieobciążony o wiariancji <span class="math inline">\(Cov(\hat\beta) = (X'X)^{-1}\sigma^2\)</span>.</p>
<p><br></p>
</section>
<section id="podaj-twierdzenie-z-dowodem-mówiące-o-postaci-macierzy-kowariancji-parametrów-modelu-liniowego." class="level2">
<h2 class="anchored" data-anchor-id="podaj-twierdzenie-z-dowodem-mówiące-o-postaci-macierzy-kowariancji-parametrów-modelu-liniowego.">6. Podaj twierdzenie z dowodem mówiące o postaci macierzy kowariancji parametrów modelu liniowego.</h2>
<p><span class="math display">\[Cov(\hat\beta) = (X'X)^{-1}\sigma^2\]</span> Ponieważ</p>
<p><span class="math display">\[\begin{array}a Cov(\hat\beta) = Cov((X'X)^{-1}X'y) = \\
(X'X)^{-1}X'Cov(y)((X'X)^{-1}X')' = \\
(X'X)^{-1}X'X(X'X)^{-1}\sigma^2 = (X'X)^{-1}\sigma^2\end{array}\]</span></p>
<p><br></p>
</section>
<section id="podaj-wzór-estymatora-wariancji-sigma2-dla-regresji-liniowej-i-podaj-jego-własności." class="level2">
<h2 class="anchored" data-anchor-id="podaj-wzór-estymatora-wariancji-sigma2-dla-regresji-liniowej-i-podaj-jego-własności.">7. Podaj wzór estymatora wariancji <span class="math inline">\(\sigma^2\)</span> dla regresji liniowej i podaj jego własności.</h2>
<p>Nieobciąonym estymatorem wariancji <span class="math inline">\(\sigma^2\)</span> w regresji wielorakiej jest</p>
<p><span class="math display">\[s^2 = \frac{e'e}{n-p-1} = \frac{1}{n-p-1}\sum\limits^n_{i=1}(y_i - \hat y_i)^2\]</span></p>
<p>Przy czym nalezny pamiętać, że jeśli <span class="math inline">\(\varepsilon \sim N(0, \sigma^2I)\)</span>, to <span class="math display">\[s^2 \sim \chi^2(n-p-1) \text{ - ma rozkład chi}^2 \text{ z }n - p -1\text{ stopniami swobody}\]</span></p>
<p><br></p>
<!-- wykład 2 -->
</section>
<section id="do-czego-służy-test-f-w-modelach-liniowych" class="level2">
<h2 class="anchored" data-anchor-id="do-czego-służy-test-f-w-modelach-liniowych">8. Do czego służy test F w modelach liniowych?</h2>
<p>Test F jest testem globalnym służącym do oceny jakości modelu w kontekście istotności statystycznej parametrów strukturalnych. Wartość statystyki F pokazuje, czy istnieje związek między zmiennymi objaśniającymi a zmienna objaśnianą. Im bardziej statystyka F różni się od 1, tym lepiej, tzn. możemy odrzucić hipotezę zerową <br> <span class="math inline">\(H_0: \beta_1 = \beta_2 = \dots = \beta_p = 0\)</span> <br> <span class="math inline">\(H_1: \beta_1 \neq 0\)</span> dla conajmniej jedngo i <br></p>
<p>Dany jest wzorem <span class="math display">\[F = \frac{\frac{SSR}{p}}{\frac{RSS}{n-p-1}}\]</span> gdzie <br> <strong>SSR</strong> jest sumą kwadratów różnicy między linią regresji, a średnią y-ków (wariancja wyjaśniana przez model)<br> <strong>RSS</strong> jest sumą kwadratów odchyleń, czyli sumą kwadratów różnic między wartością dopasowaną, a wartością w próbie. (wariancja resztowa)</p>
<p><br></p>
<p><em>Jeśli część wariancji wyjaśnianej przez model jest duża w stosunku do wariancji resztowej, to najczęściej będziemy odrzucać hipotezę H0, co oznacza, iż co najmnjej jedna ze zmiennych objaśniających użytych w modelu ma istotny wpływ na zmienną objaśnianą.</em></p>
<p><br></p>
</section>
<section id="czym-są-modele-zagnieżdżone" class="level2">
<h2 class="anchored" data-anchor-id="czym-są-modele-zagnieżdżone">9. Czym są modele zagnieżdżone?</h2>
<p>Model M* jest zagnieżdżony w modelu M gdy mozna go uzyskać poprzez usunięcie z modelu M pewnych zmiennych. Zatem model <span class="math display">\[y = X_1\beta^*_1+\varepsilon^*\]</span> jest zagnieżdżony w modelu <span class="math display">\[y = X\beta+\varepsilon=(X_1,X_2)\left( \beta_1 \atop \beta_2 \right) + \varepsilon = X_1 \beta_1 + X_2\beta_2+\varepsilon\]</span> Należy tu wyraźnie zaznaczyć, że parametry <span class="math inline">\(\beta_1\)</span> i <span class="math inline">\(\beta^*_1\)</span> mogą się różnić, ponieważ model zredukowany nie uwzględnia zestaw zmiennych <span class="math inline">\(X_2\)</span>.</p>
<p><br></p>
</section>
<section id="jakie-są-obciążenie-i-wariancja-parametrów-modeli-niedouczonych-i-przeuczonych" class="level2">
<h2 class="anchored" data-anchor-id="jakie-są-obciążenie-i-wariancja-parametrów-modeli-niedouczonych-i-przeuczonych">10. Jakie są obciążenie i wariancja parametrów modeli niedouczonych i przeuczonych?</h2>
<ul>
<li><p>Niedouczenie modelu redukuje wariancję parametrów modelu <span class="math inline">\(V\!ar(\hat\beta)\)</span> oraz wariancje predykcji <span class="math inline">\(V\!ar(y_0)\)</span>, jednocześnie powodując obciążenia obu. Można rownież wykazać, że w modelach niedouczonych estymator <span class="math inline">\(s^2\)</span> jest obciążony</p></li>
<li><p>Przeuczenie modelu powoduje wzrost wariancji obu wielkości.</p></li>
</ul>
<p><br></p>
</section>
<section id="jak-testujemy-poszczególne-efekty-w-modelu-regresji-wielorakiej" class="level2">
<h2 class="anchored" data-anchor-id="jak-testujemy-poszczególne-efekty-w-modelu-regresji-wielorakiej">11. Jak testujemy poszczególne efekty w modelu regresji wielorakiej?</h2>
<p>Można pokazać, że do testowania hipotezy <br> <span class="math inline">\(H_0: \beta_j = 0\)</span> <br> właściwy będzie test: <span class="math display">\[t = \frac{\hat\beta_j}{s\sqrt{g_{jj}}}\stackrel{\text{lub}}{=}\frac{\hat\beta_j}{\text{se}(\hat\beta_j)}\]</span> gdzie <br> <span class="math inline">\(g_{jj}\)</span> jest j-tą wielkością diagonali macierzy <span class="math inline">\((X'X)^{-1}\)</span>. <br> Przy założeniu prawdziwości hipotezy <span class="math inline">\(H_0\)</span> statystyka tam ma rozkład t-studenta z <span class="math inline">\(n-p-1\)</span> stopniami swobody. <br> <strong>UWAGA:</strong> Dla regresji prostej wartości wartości statystyki testowej t jest równa co do wartości bezwzględnej <span class="math inline">\(\sqrt{F}\)</span></p>
<p><br></p>
</section>
<section id="wymień-znane-ci-miary-dopasowania-modelu-regresji-podaj-wzory-3-z-nich." class="level2">
<h2 class="anchored" data-anchor-id="wymień-znane-ci-miary-dopasowania-modelu-regresji-podaj-wzory-3-z-nich.">12. Wymień znane Ci miary dopasowania modelu regresji (podaj wzory 3 z nich).</h2>
<p>Dotychczas poznane przez nas miary dopasowania modelu to</p>
<ul>
<li><p><span class="math inline">\(R^2\)</span> - współczynnik determinacji <span class="math display">\[R^2 = \frac{SSR}{SST}\]</span></p></li>
<li><p>RMSE - Pierwiastek błędu średnio-kwadratowego <span class="math display">\[\sqrt{\frac{1}{n}\sum\limits^n_{n=1}(y_i - \hat y_i)^2}\]</span></p></li>
<li><p>MAE - Średni błąd bezwzględny <span class="math display">\[\frac{1}{n}\sum\limits^n_{n=1}|y_i - \hat y_i|\]</span></p></li>
<li><p>PRESS</p></li>
<li><p>CP Mallow’a</p></li>
<li><p>GCV</p></li>
<li><p>AIC</p></li>
<li><p>AICc</p></li>
<li><p>BIC</p></li>
</ul>
<p><br></p>
</section>
<section id="podaj-przyczyny-i-skutki-niespełnienia-założenia-o-jednorodności-wariancji-błędów-w-modelach-regresji." class="level2">
<h2 class="anchored" data-anchor-id="podaj-przyczyny-i-skutki-niespełnienia-założenia-o-jednorodności-wariancji-błędów-w-modelach-regresji.">13. Podaj przyczyny i skutki niespełnienia założenia o jednorodności wariancji błędów w modelach regresji.</h2>
<p><u>Przyczyny</u>: najczestszymi przyczynami heterogeniczności wariancji błędu są:</p>
<ul>
<li><p>wsteczna zależność</p></li>
<li><p>brak w modelu ważnych predyktorów (skorelowanych ze zmienną zależną)</p></li>
<li><p>zła specyfikacja modelu</p></li>
<li><p>budowa modelu dla danych agregowanych (np. regresja dla średnich grupowych)</p></li>
</ul>
<p><u>Skutki</u>: Estymatory wyznaczone metodą <em>OLS</em> przy naruszeniu jednorodności wariancji są nieefektywne. Ponadto szacunki błędów estymacji parametrów <span class="math inline">\(\beta\)</span> czyli <span class="math inline">\(\text{se}(\beta)\)</span> są obciążone.</p>
<p><br></p>
</section>
<section id="podaj-przyczyny-i-skutki-niespełnienia-założenia-o-liniowym-charakterze-zależności-w-modelach-regresji." class="level2">
<h2 class="anchored" data-anchor-id="podaj-przyczyny-i-skutki-niespełnienia-założenia-o-liniowym-charakterze-zależności-w-modelach-regresji.">14. Podaj przyczyny i skutki niespełnienia założenia o liniowym charakterze zależności w modelach regresji.</h2>
<p><u>Przyczyny</u>: Charakter zależności jest nieliniowy (brak liniowości ze względu na parametry). Prawdziwa zależność ma złożony charakter, który da się opisać jedynie modelem nieliniowym (np. <span class="math inline">\(y = \beta_0 \exp(\beta_1x^{\beta_2} + \varepsilon)\)</span>). Najczęściej brak wiedzy na temat prawdziwej postaci zależności jest powodem dopasowania modelu liniowego w szerszym sensie.</p>
<p><u>Skutki</u>: Dopasowanie modelu liniowego w szerszym sensie jest niewłaściwe, dlatego zarówno użycie tego modelu do celów sterowania i predykcji jest błędem. Zaleca się ponowną specyfikację modelu, czyli modyfikację estymowanego modelu z liniowego na nieliniowy.</p>
<p><br></p>
</section>
<section id="podaj-przyczyny-i-skutki-endogeniczności-w-modelach-regresji." class="level2">
<h2 class="anchored" data-anchor-id="podaj-przyczyny-i-skutki-endogeniczności-w-modelach-regresji.">15. Podaj przyczyny i skutki endogeniczności w modelach regresji.</h2>
<p><u>Przyczyny</u>: Endogeniczność predyktora oznacza, że istnieje związek pomiędzy <span class="math inline">\(X_i\)</span>, a <span class="math inline">\(\varepsilon_i\)</span>, wówczas <span class="math inline">\(E(\varepsilon|X_i) \neq 0\)</span>. Mozilwe przyczyny takiego stanu do:</p>
<ul>
<li><p>wsteczna zależność,</p></li>
<li><p>pominięcie ważnego predyktora,</p></li>
<li><p>błędy pomiarowe zmiennych modelu,</p></li>
<li><p>zła specyfikacja modelu.</p></li>
</ul>
<p><u>Skutki</u>: fektem endogeniczności predyktorów jest obciążenie parametrów <span class="math inline">\(\hat\beta\)</span> modelu.</p>
<p><br></p>
</section>
<section id="podaj-przyczyny-i-skutki-niespełnienia-założenia-o-braku-kowariancji-pomiędzy-błędami-w-modelach-regresji." class="level2">
<h2 class="anchored" data-anchor-id="podaj-przyczyny-i-skutki-niespełnienia-założenia-o-braku-kowariancji-pomiędzy-błędami-w-modelach-regresji.">16. Podaj przyczyny i skutki niespełnienia założenia o braku kowariancji pomiędzy błędami w modelach regresji.</h2>
<p><u>Przyczyny</u>: Najczęstsze przyczyny seryjnej korelacji błędów to:</p>
<ul>
<li><p>brak w modelu ważnych predyktorów,</p></li>
<li><p>zła specyfikacja modelu,</p></li>
<li><p>błędy pomiarowe zmiennej niezależnej,</p></li>
<li><p>budowa modelu dla danych agregowanych.</p></li>
</ul>
<p><u>Skutki</u>: Estymatory parametrów modelu są nieefektywne, jeśli założenie o niezależności błędów nie jest spełnione. Ponadto, w niektórych przypadkach (regresja dla danych agregowanych) szacunki błędów standaryzowanych estymacji parametrów modelu są obciążone.</p>
<p><br></p>
</section>
<section id="czym-jest-heterogeniczność-próbkowa-i-modelowa" class="level2">
<h2 class="anchored" data-anchor-id="czym-jest-heterogeniczność-próbkowa-i-modelowa">17. Czym jest heterogeniczność próbkowa i modelowa?</h2>
<p><u>Heterogeniczność Próbkowa</u>: Powiedzmy, że analizujemy wpływ poziomu zarobków na procent budżetu jaki wydajemy na jedzenie. Można się spodziewać, że wraz ze wzrostem zarobków zmienna zależna będzie charakteryzowała się większym błędem. Wprowadzenie dodatkowej zmiennej np. “lubienie jedzenia”, spowoduje usunięcie niejednorodności, ale analizujemy wówczas nieco inny związek niż w zamierzeniach. Naszym celem było znalezienie wpływu dochodu na procent wydatków na jedzenie bez uwzględniania pozostałych czynników.</p>
<p><u>Heterogeniczność Modelu</u>: to taka niejednorodność, którą usuwa się przez wprowadzenie dodatkowej zmiennej związanej z jednym z predyktorów. Przykładowo, jeśli zależność ma charakter paraboliczny, to dla modelu liniowego w sensie ścisłym, dostrzeżemy heterogeniczność wariancji. Po wprowadzeniu zmiennej niezależnej w drugiej potędze możemy ją wyeliminować.</p>
<p><br></p>
</section>
<section id="podaj-przyczyny-i-skutki-nadmiarowości-w-modelach-regresji." class="level2">
<h2 class="anchored" data-anchor-id="podaj-przyczyny-i-skutki-nadmiarowości-w-modelach-regresji.">18. Podaj przyczyny i skutki nadmiarowości w modelach regresji.</h2>
<p><u>Przyczyny</u>: Istnieją dwa rodzaje nadmiarowości, doskonała współliniowość gdy jeden z predyktorów jest kombinacją liniową pozostałych oraz statystyczna współliniowość, kiedy predyktory modelu wykazują silne korelacje</p>
<p><u>Skutki</u>: W przypadku doskonałej współniniowości nie da się oszacować parametrów modelu metodą OLS, ponieważ macierz modelu jest źle uwarunkowana. Natomiast gdy mamy doczynienia z nadmiarowością w sensie statystycznym, to wyznacznik macierzy <span class="math inline">\(X′X\)</span> będzie bardzo bliski zera i to powoduje zawyżenie błędów standardowych estymacji parametrów modelu.</p>
<p><br></p>
</section>
<section id="jakie-są-konsekwencje-braku-normalności-wektora-błędów" class="level2">
<h2 class="anchored" data-anchor-id="jakie-są-konsekwencje-braku-normalności-wektora-błędów">19. Jakie są konsekwencje braku normalności wektora błędów?</h2>
<p>Brak normalności rozkładu błędu uniemożliwia testowanie istotności parametrów modelu jeśli próba jest mała, a odchyłka od normalności duża. Ponadto wyznaczenie przedziałow ufności dla regresji i predykcji nie są możliwe.</p>
<p><br></p>
</section>
<section id="jakie-znasz-wykresy-diagnostyczne-do-testowania-założeń-modelu-linowego" class="level2">
<h2 class="anchored" data-anchor-id="jakie-znasz-wykresy-diagnostyczne-do-testowania-założeń-modelu-linowego">20. Jakie znasz wykresy diagnostyczne do testowania założeń modelu linowego?</h2>
<ol type="1">
<li>Residuals vs Fitted - Wykres reszt względem wartości dopasowanych <br></li>
<li>Normal Q-Q - wykres kwantylowy <br></li>
<li>Scale-Location - wykres reszt standaryzowanych względem wartości dopasowanych <br></li>
<li>Cook’s distance - wykres odległości Cooka <br></li>
<li>Residuals vs Leverage - wykres reszt względem dźwigni <br></li>
<li>Cook’s dist vs Leverage - wykres odległości Cooka względem dźwigni</li>
</ol>
<p><br></p>
</section>
<section id="wymień-testy-do-weryfikacji-hipotezy-o-równości-wariancji-wektora-błędów." class="level2">
<h2 class="anchored" data-anchor-id="wymień-testy-do-weryfikacji-hipotezy-o-równości-wariancji-wektora-błędów.">21. Wymień testy do weryfikacji hipotezy o równości wariancji wektora błędów.</h2>
<ul>
<li><p>Test Breuscha-Pagana</p></li>
<li><p>Test White’a</p></li>
<li><p>Test Goldfelda-Quandta</p></li>
<li><p>Test Harrisona-McCabe’a</p></li>
</ul>
<p><br></p>
</section>
<section id="wymień-testy-do-weryfikacji-hipotezy-o-braku-seryjnej-korelacji-błędów-modelu-liniowego." class="level2">
<h2 class="anchored" data-anchor-id="wymień-testy-do-weryfikacji-hipotezy-o-braku-seryjnej-korelacji-błędów-modelu-liniowego.">22. Wymień testy do weryfikacji hipotezy o braku seryjnej korelacji błędów modelu liniowego.</h2>
<ul>
<li><p>Test Durbina-Watsona</p></li>
<li><p>Test Breuscha-Godfreya</p></li>
</ul>
<p><br></p>
</section>
<section id="wymień-testy-do-weryfikacji-hipotezy-o-liniowej-postaci-zależności-pomiędzy-zmienną-objaśnianą-i-objaśniającymi." class="level2">
<h2 class="anchored" data-anchor-id="wymień-testy-do-weryfikacji-hipotezy-o-liniowej-postaci-zależności-pomiędzy-zmienną-objaśnianą-i-objaśniającymi.">23. Wymień testy do weryfikacji hipotezy o liniowej postaci zależności pomiędzy zmienną objaśnianą i objaśniającymi.</h2>
<ul>
<li><p>Test RESET Ramseya</p></li>
<li><p>Test Rainbow</p></li>
<li><p>Tet Harveya-Colliera</p></li>
</ul>
<p><br></p>
</section>
<section id="wypowiedz-twierdzenie-mówiące-o-własnościach-macierzy-h-modelu-liniowego." class="level2">
<h2 class="anchored" data-anchor-id="wypowiedz-twierdzenie-mówiące-o-własnościach-macierzy-h-modelu-liniowego.">24. Wypowiedz twierdzenie mówiące o własnościach macierzy H modelu liniowego.</h2>
<p>Niech <span class="math inline">\(X\)</span> będzie macierzą <span class="math inline">\(n \times (p+1)\)</span> modelu o rzędzie <span class="math inline">\(p + 1&lt;n\)</span>. Wówczas elementy <span class="math inline">\(H\)</span> mają następujące własności:</p>
<ol type="1">
<li><p><span class="math inline">\((1/n)\leq h_{ii} \leq 1\)</span> dla <span class="math inline">\(i = 1,2,3,\dots,n\)</span></p></li>
<li><p><span class="math inline">\(-0.5 \leq h_{ij} \leq 0.5\)</span> dla <span class="math inline">\(i \neq j\)</span></p></li>
<li><p><span class="math inline">\(\text{Tr}(H) = \sum\limits^n_{i=1}h_{ii} = p + 1\)</span></p></li>
</ol>
<p><br></p>
</section>
<section id="czym-są-obserwacje-odstające-dobrej-i-złej-dźwigni" class="level2">
<h2 class="anchored" data-anchor-id="czym-są-obserwacje-odstające-dobrej-i-złej-dźwigni">25. Czym są obserwacje odstające, dobrej i złej dźwigni?</h2>
<ul>
<li><p><u>Obserwacje odstające</u> - obserwacje, które mają wpływ na linię regresji ale nie mają wysokiej dźwigni.</p></li>
<li><p><u>Obserwacje dobrej dźwigni</u> - obserwacje o dużej dźwigni lecz nie mające dużego wpływu na kształt modelu.</p></li>
<li><p><u>Obserwacje złej dźwigni</u> - obserwacje o dużej dźwigni, jednocześnie mające duży wpływ na model.</p></li>
</ul>
<p><img src="obrazki/obr2.png" class="img-fluid"></p>
<p><br></p>
</section>
<section id="podaj-wzór-odległości-cooka-i-powiedz-do-czego-ona-służy." class="level2">
<h2 class="anchored" data-anchor-id="podaj-wzór-odległości-cooka-i-powiedz-do-czego-ona-służy.">26. Podaj wzór odległości Cooka i powiedz do czego ona służy.</h2>
<p>W celu oceny czy dana obserwacja jest wpływowa, rozważa się następującą miarę: <span class="math display">\[D_i = \frac{(\hat\beta_{(i)}-\hat\beta)'X'X(\hat\beta_{(i)}-\hat\beta)}{(p+1)s^2}=\frac{(\hat y_{(i)}-\hat y)'(\hat y_{(i)}-\hat y)}{(p+1)s^2} = \frac{r^2_i}{p+1}\left(\frac{h_{ii}}{1-h_{ii}}\right)\]</span> gdzie <br> <span class="math inline">\(\hat\beta_{(i)}\)</span> oznacza wektor parametrów estymowany na podstawie zbioru bez i-tej obserwacji, <br> <span class="math inline">\(\hat y_{(i)}\)</span> oznacza wartość dopasowaną na podstawie danych bez i-tej obserwacji, <br> <span class="math inline">\(r_i\)</span> jest i-tą resztą standaryzowaną (czasem studentyzowaną).</p>
<p><br></p>
</section>
<section id="podaj-wzór-reszt-standaryzowanych-i-studentyzowanych." class="level2">
<h2 class="anchored" data-anchor-id="podaj-wzór-reszt-standaryzowanych-i-studentyzowanych.">27. Podaj wzór reszt standaryzowanych i studentyzowanych.</h2>
<ul>
<li><p>Reszty standaryzowane <span class="math display">\[r_i=\frac{e_i}{s\sqrt{1-h_{ii}}}\]</span></p></li>
<li><p>Reszty studentyzowane <span class="math display">\[t_i=\frac{e_i}{s_{(i)}\sqrt{1-h_{ii}}}\]</span> gdzie <br> <span class="math inline">\(s_{(i)}\)</span> oznacza błąd standardowy estymacji obliczony na podstawie zbioru pozbawionego i-tej obserwacji.</p></li>
</ul>
<p><br></p>
</section>
<section id="czym-są-miary-dffit-dfbeta-covratio" class="level2">
<h2 class="anchored" data-anchor-id="czym-są-miary-dffit-dfbeta-covratio">28. Czym są miary DFFIT, DFBETA, COVRATIO?</h2>
<p>Są to miary detekcji obserwacji nietypowych w modelu.</p>
<ul>
<li><p><u>DFFITS</u> - Statystyka ta sprawdza jak i-ta obserwacja wpływa na wartość teoretyczną wyliczoną z równiania modelu liniowego. W literaturze podaje się, że obserwacje uznaje się za wpływową, jeśli: <span class="math display">\[DFFITs_i= \frac{\hat y_i - \hat y_{i,(i)}}{s_{(i)}\sqrt{h_{ii}}}\]</span></p></li>
<li><p><u>DFBETA</u> - Statystyka ta mierzy wpływ i-tej obserwacji na każdy z estymatorów współczynników modelu liniowego. W literaturze statystycznej podaje się, że obserwację uważa się za wpływową, jeśli: <span class="math display">\[DFBETAs_i= \frac{\hat\beta_i - \hat \beta_{(i)}}{s_{(i)}\sqrt{h_{ii}}}\]</span></p></li>
<li><p><u>COVRATIO</u> - Statystyka ta mierzy zmianę wyznacznika macierzy kowariancji oszacowań poprzez usunięcie i-tej obserwacji.W literaturze sugeruje się, że obserwacje spełniające warunek: <span class="math display">\[COVRATIO_i= \frac{\det(\hat\sigma^2_{(i)}(X'_{(i)}X_{(i)})^{-1})}{\det(\hat\sigma^2(X'X)^{-1})}\]</span> gdzie <br> <span class="math inline">\(\hat y_{i,(i)}\)</span> - wartość dopasowana, <br> <span class="math inline">\(\hat\beta_i\)</span> - parametr modelu, <br> <span class="math inline">\(\hat\sigma^2_{(i)}\)</span> - wariancja modelu, <br> <span class="math inline">\(X_{(i)}\)</span> - macierz predyktorów modelu <br> w kótrym usunięto i-tą obserwację</p></li>
</ul>
<p><br></p>
</section>
<section id="opisz-metodę-największej-wiarogodności-wiarygodności-w-kontekście-modeli-liniowych." class="level2">
<h2 class="anchored" data-anchor-id="opisz-metodę-największej-wiarogodności-wiarygodności-w-kontekście-modeli-liniowych.">29. Opisz metodę największej wiarogodności (wiarygodności) w kontekście modeli liniowych.</h2>
<p>Metoda największej wiarygodności jest inną metodą szacowania parametrów modeli liniowych. Opiera się o maksymalizację funkcji wiarygodności <span class="math inline">\(L(\beta,\sigma^2)\)</span>. Jeśli rozkład zmiennej y (lub błędu ε) jest normalny, to maksimum można uzyskać znajdując pochodne cząstkowe.</p>
<p><br></p>
</section>
<section id="podaj-własności-estymatora-parametrów-modelu-otrzymanego-metodą-największej-wiarogodności." class="level2">
<h2 class="anchored" data-anchor-id="podaj-własności-estymatora-parametrów-modelu-otrzymanego-metodą-największej-wiarogodności.">30. Podaj własności estymatora parametrów modelu otrzymanego metodą największej wiarogodności.</h2>
<ul>
<li><p><span class="math inline">\(\hat\beta\sim N(\beta, \sigma^2(X'X)^{-1})\)</span> - <span class="math inline">\(\hat\beta\)</span> ma rozkład normalny o średniej równej <span class="math inline">\(\beta\)</span> i wariancji równej <span class="math inline">\(\sigma^2(X'X)^{-1}\)</span>,</p></li>
<li><p><span class="math inline">\(\frac{(n-p-1)s^2}{\sigma^2} \sim \chi^2(n-p-1)\)</span> - <span class="math inline">\((n-p-1)s^2\)</span> oraz <span class="math inline">\(\sigma^2\)</span> ma rozkład <span class="math inline">\(\chi^2\)</span> o <span class="math inline">\((n-p-1)\)</span> stopniach swobody, gdzie <span class="math inline">\(s^2\)</span> to wariancja z próby, a <span class="math inline">\(\sigma^2\)</span> to wariancja z populacji,</p></li>
<li><p><span class="math inline">\(\hat\beta\)</span> i <span class="math inline">\(s^2\)</span> są niezależne.</p></li>
</ul>
<p><br></p>
</section>
<section id="czym-jest-przedział-ufności-dla-regresji-i-predykcji" class="level2">
<h2 class="anchored" data-anchor-id="czym-jest-przedział-ufności-dla-regresji-i-predykcji">31. Czym jest przedział ufności dla regresji i predykcji?</h2>
<p><u>Przedział ufności dla regresji</u> informuje o tym, jak dokładnie oszacowaliśmy parametr rozkładu cechy populacji na podstawie próby. Dokładniej pobierając wielokrotnie próbę w tych samych warunkach i tej samej wielkości, otrzymujemy pewną liczbę przedziałów, z których 95% będzie zawierało prawdziwą wartość szacownego parametru rozkładu cechy populacji.Przedział ufności opisuje jak dokładnie oszacowaliśmy parametr rozkładu cechy populacji na podstawie próby. Przedział ufności dotyczy statystyki oszacowanej na podstawie wielu obserwacji i wyraża niepewność pobierania próby.W przypadku modelu liniowego możemy zbudować przedział ufności dla każdego współczynnika tego modelu. Przedziały ufności dla parametrów pokazują zakres, w jakim z zadanym prawdopodobieństwem „znajdują się ich prawdziwe wartości”. Dokładniej Przedziały ufności dla regresji z zadanym prawdopodobieństwem pokrywają nieznane wartości współczynników modelu.</p>
<p><u>Przedział ufności dla predykcji</u> naczej przedział ufności dla prognozy informuje jakiej wartości zmiennej objaśnianej można się spodziewać na podstawie zbudowanego modelu liniowego, dla zadanych wartości zmiennych objaśniających. Przedziały dla prognozy uwzględniają zarówno niepewność znajomości wartości średniej populacji, jaki rozrzut danych, tak więc są one zawsze szerszy niż przedział ufności dla regresji</p>
<p><br></p>
</section>
<section id="jakie-są-powody-transformacji-zmiennych-objaśniających-i-objaśnianych-w-modelach-liniowych" class="level2">
<h2 class="anchored" data-anchor-id="jakie-są-powody-transformacji-zmiennych-objaśniających-i-objaśnianych-w-modelach-liniowych">32. Jakie są powody transformacji zmiennych objaśniających i objaśnianych w modelach liniowych?</h2>
<p>Istnieją trzy główne powody transformacji zmiennych modelu, są to:</p>
<ul>
<li><p>korekta niejednorodności wariancji błędu modelu,</p></li>
<li><p>wymuszenie normalności rozkładu błędu modelu,</p></li>
<li><p>estymacja efektów procentowych.</p></li>
</ul>
<p>Pierwsze dwa problemy dotyczą założeń modelu i istnieje kilka metod znajdowania odpowiedniej formy funkcyjnego przekształcenia zmiennej zależnej, zmiennych niezależnych lub wszystkich jednocześnie. Ostatni powód wynika z chęci uzyskania odpowiedniej postaci efektu. Czasami interesuje nas jak zmienna procentowa zmiennej niezależnej skutkuje zmianą procentową zmiennej zależnej.</p>
<p><br></p>
</section>
<section id="jak-interpretować-model-którego-zmienne-są-logarytmowane" class="level2">
<h2 class="anchored" data-anchor-id="jak-interpretować-model-którego-zmienne-są-logarytmowane">33. Jak interpretować model, którego zmienne są logarytmowane?</h2>
<p>Załóżmy hipotetyczne model, który posiada zmienne “cena” i “sprzedaż”. Skupiając się na efekcie obniżki procentowej ceny i jej wpływie na procentowy wzrost sprzedaży dokonujemy logarytmowania zmiennych. Wtedy dany model powinno interpretować się w następujący sposób, że przykładowo podwyższenie ceny produktów o <span class="math inline">\(1\%\)</span> powoduje obniżenie popytu (sprzedaży) o <span class="math inline">\(5.1\%\)</span>.</p>
<p>Można również rozpatrywać modele typu <span class="math display">\[y = \beta_0 + \beta_1\log(x) + \varepsilon\]</span> Wówczas wzrost cechy <span class="math inline">\(x\)</span> o <span class="math inline">\(1\%\)</span> powoduje zmianę cechy <span class="math inline">\(y\)</span> o <span class="math inline">\(\beta_1\)</span> jednostek, w których mierzono <span class="math inline">\(y\)</span>. Natomiast model <span class="math display">\[\log(y) = \beta_0 + \beta_1x+\varepsilon\]</span> mówi, że wzrost cechy <span class="math inline">\(x\)</span> o jedną jednostkę, powoduję zmianę cechy <span class="math inline">\(y\)</span> o <span class="math inline">\(\beta_1\%\)</span></p>
<p><br></p>
</section>
<section id="czym-jest-przekształcenie-potęgowe-i-do-czego-służy" class="level2">
<h2 class="anchored" data-anchor-id="czym-jest-przekształcenie-potęgowe-i-do-czego-służy">34. Czym jest przekształcenie potęgowe i do czego służy?</h2>
<p>Aby oszacować postać funkcji <span class="math inline">\(g^{−1}\)</span> będziemy stosować rodzinę przekształceń potęgowych postaci <span class="math display">\[\Psi (y,\lambda) =
\begin{cases}
\frac{y^\lambda-1}{\lambda}, \quad \; \; y \neq 0 \\
\log(y), \quad y= 0
\end{cases}\]</span> Powyższa funkcja ma nastepujące własności:</p>
<ul>
<li><p><span class="math inline">\(\Psi (y,\lambda)\)</span> jest ciągła <span class="math inline">\(\lambda\)</span>.</p></li>
<li><p>Przekształcenie logarytmiczne jest częścią rodziny przekształceń, bo <span class="math display">\[\lim\limits_{\lambda \rightarrow 0}\frac{y^\lambda-1}{\lambda}=\log(y)\]</span></p></li>
<li><p><span class="math inline">\(\Psi (y,\lambda)\)</span> zachowuje kierunek zależności (znak korelacji).</p></li>
</ul>
<p><br></p>
</section>
<section id="na-czym-polega-transformacja-box-cox-i-czym-się-różni-od-transformacji-yeo-johnsona" class="level2">
<h2 class="anchored" data-anchor-id="na-czym-polega-transformacja-box-cox-i-czym-się-różni-od-transformacji-yeo-johnsona">35. Na czym polega transformacja Box-Cox i czym się różni od transformacji Yeo-Johnsona?</h2>
<p>Metoda Box’a - Cox’a opiera się na takiej transformacji zmiennych, aby zmaksymalizować funkcję wiarygodności. Poprawiona transformacja Box’a - Cox’a przyjmuje postać:</p>
<p><span class="math display">\[\Phi_{BC}(y,\lambda) = \Psi(y,\lambda) \times gm(y)^{1-\lambda} = \begin{cases}
gm(y)^{1-\lambda}\frac{y^\lambda-1}{\lambda}, \quad y \neq 0 \\
gm(y)\log(y), \quad \; \: \,y = 0
\end{cases}\]</span></p>
<p>gdzie <span class="math inline">\(gm(y)\)</span> = <span class="math inline">\(\prod\limits^n_{i=1}y^{\frac{1}{n}}_i\)</span> jest średnią geometryczną, a <span class="math inline">\(y\)</span> przyjmuje tylko wartości dodatnie. Wówczas maksymalizacja funkcji wiarygodności sprowadza się do minimalizacji <span class="math display">\[RSS(\lambda)=\sum\limits^n_{i=1}(\Phi_{BC}(y_i,\lambda)-\hat\beta_0 - \hat\beta_1x_i)^2\]</span> Jedyną niedogodnością w stosowaniu klasycznej transformacji Box’a-Cox’a jest wymóg aby <span class="math inline">\(y &gt; 0\)</span>. Rozwiązaniem tego problemu jest modyfikacja przekształcenia Box’a-Cox’a autorstwa Yeo-Johnson’a <span class="math display">\[\Phi_{YJ}(y,\lambda) =
\begin{cases}
\Phi_{BC}(y+1,\lambda), \quad \quad y \geq 0 \\ \Phi_{BC}(1-y,2-\lambda), \; y &lt; 0
\end{cases}\]</span></p>
<p><br></p>
</section>
<section id="opisz-zasadę-działania-ważonej-metody-najmniejszych-kwadratów." class="level2">
<h2 class="anchored" data-anchor-id="opisz-zasadę-działania-ważonej-metody-najmniejszych-kwadratów.">36. Opisz zasadę działania ważonej metody najmniejszych kwadratów.</h2>
<p>Przypadkiem uogólnionego modelu regresji liniowej, w którym nie występuje zależność między resztami modelu jest ważony model regresji liniowej (WLS - Weighted Least Squares). W tym przypadku estymacja parametrów modelu polega na “zważeniu” obserwacji poprzez podzielenie ich (unormowanie) przez odchylenie standardowe, a następnie wyznaczenie estymatora OLS. W szczególności, dostajemy tzw.bezwarunkową homoskedastyczność, która nie implikuje warunkowej homoskedastyczności. Jednakże estymator WLS zwiększa jakość estymacji.</p>
<p><br></p>
</section>
<section id="na-czym-polega-metoda-fwls-fgls" class="level2">
<h2 class="anchored" data-anchor-id="na-czym-polega-metoda-fwls-fgls">37. Na czym polega metoda FWLS (FGLS)?</h2>
<p>W przypadku gdy nie znamy macierzy kowariancji V ale wiemy, że jest funkcją pewnego predyktora, to zaleca się stosowanie metody FGLS (czasem oznaczana jako FWLS). Polega ona na estymowaniu parametrów modelu w dwóch krokach:</p>
<ul>
<li><p>Estymacja parametrów <span class="math inline">\(\beta\)</span> metodą OLS.</p></li>
<li><p>Estymacja modelu <span class="math inline">\(\ln(e^2) = \gamma_0 + \gamma_1x_1 + \dots + \gamma_px_p\)</span>, gdzie <span class="math inline">\(e\)</span> są resztami z modelu OLs. W niektórych publikacjach zaleca się stosować inne funkcje zależności reszt od predyktorów.</p></li>
<li><p>Wyznaczamy odpowiedzi modelu z punktu 2 i przyjmujemy, że <span class="math inline">\(h_i=\exp(\ln(\hat e^2))\)</span> dla <span class="math inline">\(i = 1, \dots, n\)</span>.</p></li>
<li><p>Estymujemy model WLS, przyjmując <span class="math inline">\(\frac{1}{h_i}\)</span> jako oszacowania wag.</p></li>
</ul>
<p><br></p>
</section>
<section id="czym-są-estymatory-whitea" class="level2">
<h2 class="anchored" data-anchor-id="czym-są-estymatory-whitea">38. Czym są estymatory White’a?</h2>
<p>W przypadku gdy nie znamy macierzy kowariancji V i nie znamy struktury zależności wariancji od predyktorów, stosujemy odporne estymatory błędów standardowych White’a. Przyjmują one postać: <span class="math display">\[\hat{V\!ar}(\hat\beta) = (X'X)^{-1}X'diag(e^2)X(X'X^{-1})\]</span> gdzie <br> <span class="math inline">\(e^2\)</span> oznaczają kwadraty reszt modelu OLS, a <span class="math inline">\(X\)</span> jest macierzą modelu. Pierwiastek z wariancji opisanej wyżej jest odpornym estymatorem błędu standardowego estymacji. Estymatory odporne nie zmieniają parametrów modelu, a jedynie macierz ich kowariancji.</p>
<p><br></p>
</section>
<section id="czym-jest-i-do-czego-służy-ancova" class="level2">
<h2 class="anchored" data-anchor-id="czym-jest-i-do-czego-służy-ancova">39. Czym jest i do czego służy ANCOVA?</h2>
<p><u>Analiza kowariancji (<strong>ANCOVA</strong> - <strong>AN</strong>alysis of <strong>COVA</strong>riance)</u> to często stosowana metoda statystyczna łącząca w sobie elementy analizy wariancji (<strong>ANOVA</strong> - <strong>AN</strong>alysis <strong>O</strong>f <strong>VA</strong>riance), korelacji i regresji. Główny cel metody jest podobny do analizy wariancji: dać odpowiedź czy analizowany czynnik doświadczalny wpływa w sposób istotny na badaną cechę. Na przykład, możemy mieć do czynienia z dwiema różnymi metodami nauczania matematyki w dwóch różnych klasach (grupach/próbach). Obok oceny biegłości w matematyce możemy zbierać także dane na temat ogólnej inteligencji. Może być interesującym przekonać się czy zależność między ogólną inteligencją a wynikami w matematyce jest silniejsza czy słabsza w zależności od metody nauczania. W terminologii ANCOVA taka hipoteza odnosi się do równoległości linii regresji w obydwu klasach. Jeśli linie te są równoległe to zależności w obu klasach są takie same i stąd wynika, że związek między inteligencją a wynikami w matematyce nie zależy od metody nauczania. Jeśli nie są one równoległe to wnioskujemy, że metoda nauczania ma wpływ na zależność wyników od inteligencji.</p>
<p>W analizie kowariancji budujemy model regresji liniowej, w którym występuje pośród zmiennych objaśniających co najmniej jedna zmienna ilościowa i co najmniej jedna zmienna jakościowa. Jeśli zmienna jakościowa <span class="math inline">\(V\)</span> ma <span class="math inline">\(k\)</span> poziomów, to kodujemy ją następująco: jeden z tych poziomów określamy jako referencyjny, a dla każdego pozostałego poziomu tworzymy zmienną charakterystyczną zwaną zmienną pustą i te zmienne umieszczamy w modelu.</p>
<p><br></p>
</section>
<section id="czym-jest-regresja-wielomianowa-i-jak-można-ją-wykorzystać-w-modelowaniu-zależności-pomiędzy-cechami" class="level2">
<h2 class="anchored" data-anchor-id="czym-jest-regresja-wielomianowa-i-jak-można-ją-wykorzystać-w-modelowaniu-zależności-pomiędzy-cechami">40. Czym jest regresja wielomianowa i jak można ją wykorzystać w modelowaniu zależności pomiędzy cechami?</h2>
<p><u>Regresja wielomianowa</u> - czasami zdarza się, że postać zależności nie da się opisać liniowo (w sensie ścisłym). Nawet jeśli prawdziwa postać nie da się opisać wielomianem rzędu m, to wiele z nich da się aproksymować za pomocą wielomianów.</p>
<p><img src="obrazki/obr1.png" class="img-fluid"> <u><em>Interpretacja wyników</em></u> <br> Na podstawie tabeli możemy wywnioskować, że wielomian 2 stopnia jest odpowiednim opisem zależności. Model liniowy wyraźnie nie opisuje właściwości badanej zależności. Natomiast wielomian 3 stopnia nie poprawia znacząco jakości dopasowania, jednocześnie zawyżając błędy standardowe estymacji, ponieważ jest nadmiernie dopasowany <br> <strong>Uwaga</strong> Pamiętajmy, że podobnie jak w przypadku analizy kowariancji, tak i w tym przypadku nie usuwamy efektów niższego rzędu jeśli efekty wyższych rzędów są istotne.</p>
<p><br></p>
</section>
<section id="przeprowadź-dyskusję-na-temat-naruszeń-założeń-modelu-anova." class="level2">
<h2 class="anchored" data-anchor-id="przeprowadź-dyskusję-na-temat-naruszeń-założeń-modelu-anova.">41. Przeprowadź dyskusję na temat naruszeń założeń modelu ANOVA.</h2>
<p>Właściwe przeprwadzenie testu wymaga spelnienia pewnych założeń:</p>
<ul>
<li><p>Pierwszym z nich jest normalność próby w badanych grupach lub normalność zmiennej objaśnianej. Oba warunki przy założeniu, że model poprawnie został określony, są równoważne. Można się oczywiście zdarzyć, że niektóre rozkłady zmiennej objaśnianej w badanych grupach nie będą normalne, a zmienna y nie dzielona na grupy ma rozkład normalny. Wówczas prawdopodobnie brakuje w modelu zmiennych, które mają istotny wpływ na zmienną y, a przez to, że nie zostały ujęte w modelu, zakłócenia nie są losowe. Dobrym rozwiązaniem jest wówczas włączyć do modelu takie zmienne.</p></li>
<li><p>Drugim założeniem jest jednorodność wariancji reszt. Nie spełnienie tego założenia również może być spowodowane brakiem istotnych zmiennych w modelu lub istnieniem przypadków odstających.</p></li>
<li><p>Szczególnym przypadkiem niejednorodności wariancji reszt jest sytuacja kiedy odchylenia standardowe reszt są skorelowane ze średnimi w grupach.</p></li>
</ul>
<p><br></p>
<p>Istnieje wiele prac (Lindman 1974, Box i Anderson 1955) na temat wpływu niespełnienia poszczególnych założeń na moc testu. Twierdzą one, że test F jest odporny na brak normalności efektu losowego. Szczególnie małe znaczenie ma to założenie w przypadku dużych liczebności w podgrupach. W przypadku małych prób, które nie spełniają założenia o normalności, należy zwrócić szczególną uwagę na kurtozę rozkładu. Ma ona większe znaczenie niż skośność i w przypadku gdy jest większa od 0 powoduje zaniżenie wartości F. Test F wykazuje też dużą odporność na niejednorodność wariancji reszt. Jak pokazał Lindman w swojej pracy jeśli tylko odchylenia standardowe nie są skorelowane ze średnimi, to test F będzie pokazywał właściwe wyniki. U podstaw właściwego przeprowadzenia testu ANOVA leżą dwie zasady randomizacji. Pierwsza z nich głosi, że “dobór elementów do próby powinien być losowy”, a druga “dobór elementów do poszczególnych poziomów czynnika jakościowego powinien się odbywać w sposób losowy”. Nie zawsze jest możliwe spełnienie obu założeń. Trzeba wówczas zatroszczyć się o to, aby były w miarę równoliczne. W przypadku niespełnienia jakiegokolwiek z wyżej wymienionych założeń dobrą praktyką jest stosowanie nieparametrycznego odpowiednika analizy wariancji, czyli testu Kruskala - Wallisa.</p>
<p><br></p>
</section>
<section id="wymień-znane-ci-testy-post-hoc-oraz-określ-podobieństwa-i-różnice-pomiędzy-nimi." class="level2">
<h2 class="anchored" data-anchor-id="wymień-znane-ci-testy-post-hoc-oraz-określ-podobieństwa-i-różnice-pomiędzy-nimi.">42. Wymień znane Ci testy post-hoc oraz określ podobieństwa i różnice pomiędzy nimi.</h2>
<ul>
<li><p><u>Test HSD Tukeya</u> jest oparty na statystyce testowej studentyzowanego rozstępu wyznaczonej jako różnica pomiędzy najmniejszą a największą średnią w rozważanych grupach podzieloną przez pierwiastek z wariancji wewnątrzgrupowej. Test ten powinien być stosowany tylko do układu zrónoważonego (równoliczne grupy). Dla układów niezrównoważonych stosuje się test Spjotvolla i Stoline’a.</p></li>
<li><p><u>Test Newmana-Keulsa</u> ma podobną budowę do testu Tukeya, z jedną różnicą. Mianowicie, jeżeli rozważamy k grup, to w teście Tukeya dla każdej pary średnich stosuje się ten sam kwantyl studentyzowanego rozkładu rozstępu dla k grup. W teście Newmana-Keulsa średnie w pierwszym kroku są sortowane, następnie jeżeli porównuje się średnią, <span class="math inline">\(\hat\mu_{1:k}\)</span> (najmniejszą) z <span class="math inline">\(\hat\mu_{k:k}\)</span> (największą), to stosuje się rozkład studentyzowanego rozstępu dla k grup. Ale dla innych średnich, stosuje się rozkład studentyzowany dla <span class="math inline">\(|i − j| + 1\)</span> grup.</p></li>
<li><p><u>Test LSD Fishera</u> Polega on na wykonaniu <span class="math inline">\(\frac{k(k1)}{2}\)</span> testów t-Studenta przez porównanie każdej pary średnich i zastosowanie korekty na liczbę przeprowadzonych testów. Do korekty wykorzystać można poprawkę np. Bonferroniego, Holma-Hochberga. Nie zakłada się tutaj równych liczebności grup.</p></li>
<li><p><u>Test Scheffe</u> Jest to najbardziej konserwatywny test, czyli najlepiej kontroluje błąd I rodzaju ale też ma najmniejszą czułość. Przypomina test LSD Fishera, ale tu są uwzględnione wszystkie możliwe kontrasty. Z tego powodu mimo konserwatywności, jest on używany w sytuacji, gdy porównywane są nieplanowane kontrasty. Nie zakłada się tutaj równych liczebności grup.</p></li>
</ul>
<p><br></p>
</section>
<section id="czym-są-porównania-zaplanowane" class="level2">
<h2 class="anchored" data-anchor-id="czym-są-porównania-zaplanowane">43. Czym są porównania zaplanowane?</h2>
<p>Porównanie wszystkich par średnich ze sobą nie zawsze jest tym, co nas interesuje. W wielu sytuacjach chcemy porównać wybrane średnie lub grupy średnich pomiędzy sobą. Do porównania wybranych grup średnich służy analiza kontrastów (porównania zaplanowane). Kontrastem nazywamy liniową funkcję średnich <span class="math display">\[L = \sum\limits^k_{i=1}c_i\mu_i\]</span> gdzie <br> najczęściej zakłada się, że <span class="math inline">\(\sum\limits^k_{i=1}c_i = 0\)</span></p>
<p>Przykładowo, jeśli badamy wpływ czynnika kontrolowanego na trzech poziomach i chcemy sprawdzić, czy pierwsza z tych grup różni się od pozostałych, to hipoteza zerowa ma postać <br> <span class="math inline">\(H_0:\mu = \frac{\mu_2+\mu_3}{2}\)</span> <br> co możemy zapisać w postaci <br> <span class="math inline">\(H_0:\mu - \frac{1}{2}\mu_2 - \frac{1}{2}\mu_3 = 0 \quad\)</span> lub <span class="math inline">\(\quad H_0:2\mu - \mu_2 - \mu_3 = 0\)</span></p>
<p>Aby przetestować tę hipotezę należy przypisać wagi <span class="math inline">\(c_1=2; \; c_2 = -1; \; c_3=-1\)</span> odpowiednim średnim. Współczynniki zbioru kontrastów można przedstawić, używając macierzy <span class="math inline">\(k \times m\)</span> <br> gdzie <br> <span class="math inline">\(m\)</span> to liczba kontrastów, <br><span class="math inline">\(k\)</span> to liczba współczynników opisujących każdy kontrast.</p>
<p><br></p>
</section>
<section id="podaj-przykłady-trzech-predefiniowanych-kontrastów." class="level2">
<h2 class="anchored" data-anchor-id="podaj-przykłady-trzech-predefiniowanych-kontrastów.">44. Podaj przykłady trzech predefiniowanych kontrastów.</h2>
<div style="display: flex;">
<div>
<p><u>Odchylenie</u> </p>
</div>
<div>
<p>kontrast służący do porówniania odchyleń każdej średniej grupowej od średniej ogólnej zmiennej zależnej. Na przykład dla czynnika o trzech poziomach, jeśli chcemy porównać <span class="math inline">\(\mu_1\)</span> z <span class="math inline">\(\frac{\mu_1+\mu_2+\mu_3}{3}\)</span>, mamy <span class="math inline">\(2\mu_1-\mu_2-\mu_3=0\)</span>, czyli dostajemy kontrast <span class="math inline">\((2,-1,-1)\)</span>. Podobnie porównując <span class="math inline">\(\mu_2\)</span> z <span class="math inline">\(\frac{\mu_1+\mu_2+\mu_3}{3}\)</span>, dostajemy kontrst <span class="math inline">\((-1,2,-1)\)</span>.</p>
</div>
</div>
<div style="display: flex;">
<div>
<p><u>Prosty</u>   </p>
</div>
<div>
<p>ten kontrast służy do porównywania średniej dla każdego poziomu ze średnią ostatniego poziomu. Dla trzech poziomów otrzymujemy macierzkonstastów: <span class="math inline">\((1,0,-1), \; (0,1,-1)\)</span>.</p>
</div>
</div>
<div style="display: flex;">
<div>
<p><u>Powtarzany</u> </p>
</div>
<div>
<p>ten kontrast służy do porównywania średnich sąsiednich poziomów czynnika. Dla trzech poziomów mamy macierz kontrastów: <span class="math inline">\((1,0,-1), \; (0,1,-1)\)</span>.</p>
</div>
</div>
<p><br></p>
</section>
<section id="czym-są-kontrasty-ortogonalne" class="level2">
<h2 class="anchored" data-anchor-id="czym-są-kontrasty-ortogonalne">45. Czym są kontrasty ortogonalne?</h2>
<p>Dwa kontrasty <span class="math inline">\(K_1 = \sum\limits^k_{i=1} c_{1i}\mu_i\)</span> i <span class="math inline">\(K_2 = \sum\limits^k_{i=1} c_{2i}\mu_i\)</span> są względem siebie ortogonalne, gdy suma iloczynów odpowiadających sobie wag jest równa zero (niezależność wektorów), czyli <span class="math inline">\(\sum\limits^k_{i=1} c_{1i}c_{2i} = 0\)</span>. Zbiór <span class="math inline">\(m\)</span> kontrastów tworzy zbiór kontrastów względem siebie ortogonalny, gdy wszystkie pary kontrastów w tym zbiorze są ortogonalne.</p>
<ul>
<li><p>Dla zbioru <span class="math inline">\(k\)</span> średnich możemy utworzyć maksymalnie <span class="math inline">\(k − 1\)</span> kontrastów ortogonalnych.</p></li>
<li><p>Suma sum kwadratów <span class="math inline">\(k − 1\)</span> ortogonalnych kontrastów daje sumę kwadratów dla efektu badanego czynnika.</p></li>
<li><p>Rozkład sumy kwadratów na kontrasty ortogonalne nie jest jednoznaczny (możemy budować różne zbiory kontrastów ortogonalnych).</p></li>
<li><p>Nie musimy badać wszystkich kontrastów ortogonalnych. Najczęściej rozpatrujemy konkretne interesujące nas kontrasty badawcze. Pozostałe kontrasty można powiązać w efekt łączny, tworząc kontrast pomiędzy średnimi wykorzystanymi i niewykorzystanymi w dotychczasowych kontrastach.</p></li>
</ul>
<p>Miara <span class="math inline">\(r^2 = \frac{SS_K}{SS_{\text{efektu}}}\)</span> wyrażana w procentach, informuje w jakim procencie dany kontrast wyjaśnia zmienność wśród zmiennych grupowych.</p>
<p><br></p>
</section>
<section id="na-czym-polegają-różnice-w-typach-testów-i-ii-iii-anova" class="level2">
<h2 class="anchored" data-anchor-id="na-czym-polegają-różnice-w-typach-testów-i-ii-iii-anova">46. Na czym polegają różnice w typach testów (I, II, III) ANOVA?</h2>
<p>Do lepszego zrozumienia powyższej uwagi przyjrzyjmy się jak testy różnych typów testują poszczególne hipotezy. Po pierwsze należy wprowadzić pewne oznaczenia, które pozwolą rozróżniać sumy kwadratów odchyleń:</p>
<ul>
<li><p><span class="math inline">\(SS(A|B) = SS(A,B)- SS(B)\)</span>,</p></li>
<li><p><span class="math inline">\(SS(B|A) = SS(A,B)- SS(A)\)</span>,</p></li>
<li><p><span class="math inline">\(SS(AB|A,B) = SS(A,B,AB)- SS(A,B)\)</span>,</p></li>
<li><p><span class="math inline">\(SS(A|B,AB) = SS(A,B,AB)- SS(B,AB)\)</span>,</p></li>
<li><p><span class="math inline">\(SS(B|A,AB) = SS(A,B,AB)- SS(A,AB)\)</span>,</p></li>
</ul>
<p>gdzie <br> skrót <span class="math inline">\(SS\)</span> oznacza sumę kwadratów odchyleń uwzględniająca wskazane w nawiasie efekty.</p>
<section id="test-typu-i" class="level3">
<h3 class="anchored" data-anchor-id="test-typu-i"><strong>Test typu I</strong></h3>
<p>(sekwencyjny) w modelu z interakcją testuje w następującej kolejności poszczególne efekty:</p>
<ul>
<li><p><span class="math inline">\(SS(A)\)</span> - test efektu <span class="math inline">\(A\)</span></p></li>
<li><p><span class="math inline">\(SS(B|A)\)</span> - testuje istotność efektu <span class="math inline">\(B\)</span> przy założeniu, że z sumy kwadratów odchyleń został już usunięty wpływ efektu czynnika <span class="math inline">\(A\)</span>,</p></li>
<li><p><span class="math inline">\(SS(AB|A,B)\)</span> - testuje efekt interakcji <span class="math inline">\(AB\)</span>, przy założeniu, że z sumy kwadratów odchyleń zostały usunięte efekty <span class="math inline">\(A\)</span> i <span class="math inline">\(B\)</span>.</p></li>
</ul>
<p><u>Zalety</u><br></p>
<ul>
<li><p><span class="math inline">\(SS\)</span> poszczególnych efektów sumują się do SST,</p></li>
<li><p>odpowiedni do badania efektów zagnieżdżonych,</p></li>
<li><p>wyniki nie zależą od kontrastów.</p></li>
</ul>
<p><u>Wady</u><br></p>
<ul>
<li><p>kolejność włączanych efektów jest ważna,</p></li>
<li><p>niewłaściwe dla większości testowanych hipotez.</p></li>
</ul>
</section>
<section id="test-typu-ii" class="level3">
<h3 class="anchored" data-anchor-id="test-typu-ii"><strong>Test typu II</strong></h3>
<ul>
<li><p><span class="math inline">\(SS(A|B)\)</span> - testuje efekt <span class="math inline">\(A\)</span> przy założeniu, że wpływ efektu <span class="math inline">\(B\)</span> został już usunięty.</p></li>
<li><p><span class="math inline">\(SS(B|A)\)</span> - testuje istotność efektu <span class="math inline">\(B\)</span> przy założeniu, że z sumy kwadratów odchyleń został już usunięty wpływ efektu czynnika <span class="math inline">\(A\)</span>,</p></li>
<li><p><span class="math inline">\(SS(AB|A,B)\)</span> - testuje efekt interakcji <span class="math inline">\(AB\)</span>, przy założeniu, że z sumy kwadratów odchyleń zostały usunięte efekty <span class="math inline">\(A\)</span> i <span class="math inline">\(B\)</span>.</p></li>
</ul>
<p><u>Zalety</u><br></p>
<ul>
<li><p>najmocniejszy test przy braku interakcji,</p></li>
<li><p>właściwy do oceny istotności efektów w trakcie budowy modelu hierarchicznie,</p></li>
<li><p>kolejność włączanych efektów jest nieistotna,</p></li>
<li><p>wyniki nie zależą od kontrastów,</p></li>
<li><p><span class="math inline">\(SS\)</span> efektów sumują się do SST.</p></li>
</ul>
<p><u>Wady</u><br></p>
<ul>
<li>nie jest odpowiedni w przypadku istotnych interakcji efektów brzegowych.</li>
</ul>
</section>
<section id="test-typu-iii" class="level3">
<h3 class="anchored" data-anchor-id="test-typu-iii"><strong>Test typu III</strong></h3>
<p>(brzegowy):</p>
<ul>
<li><p><span class="math inline">\(SS(A|B,AB)\)</span> - test efektu <span class="math inline">\(A\)</span> przy wyłączeniu wpływu czynnika <span class="math inline">\(B\)</span> i interakcji <span class="math inline">\(AB\)</span>,</p></li>
<li><p><span class="math inline">\(SS(B|A,AB)\)</span> - test efektu <span class="math inline">\(B\)</span> przy wyłączeniu wpływu czynnika <span class="math inline">\(A\)</span> i interakcji <span class="math inline">\(AB\)</span>,</p></li>
<li><p><span class="math inline">\(SS(AB|A,B)\)</span> - testuje efekt interakcji <span class="math inline">\(AB\)</span> przy wyłączeniu wpływu czynników <span class="math inline">\(A\)</span> i <span class="math inline">\(B\)</span>.</p></li>
</ul>
<p><u>Zalety</u><br></p>
<ul>
<li>kolejność efektów nie ma znaczenia.</li>
</ul>
<p><u>Wady</u><br></p>
<ul>
<li><p>tylko dla kontrastów ortogonalnych do wyrazu wolnego są sensowne,</p></li>
<li><p>tylko dla kontrastów ortogonalnych do wyrazu wolnego są sensowne,</p></li>
<li><p>średnie globalna i brzegowe nie uwzględniają niezbalansowania układu,</p></li>
<li><p>trudne do interpretacji wielkości efektów brzegowych w przypadku istotnej interakcji.</p></li>
</ul>
<!-- <br/> -->
<!-- ## 47. Podaj ogólną zasadę tworzenia modeli GLM. -->
<!-- <br/> -->
<!-- ## 48. Czym jest i do czego służy regresja logistyczna? -->
<!-- <br/> -->
<!-- ## 49. Jak testujemy istotność efektów w modelach GLM? -->
<!-- <br/> -->
<!-- ## 50. Na czym polega metoda Gaussa-Newtona? -->
<!-- <br/> -->
<!-- ## 51. Czy jest hierarchiczna analiza wariancji? -->
<!-- <br/> -->
<!-- ## 52. Na czym polegają efekty stałe i losowe w modelach mieszanych? -->
<!-- <br/> -->
<!-- ## 53. Wymień znane Ci testy istotności efektów stałych. -->
<!-- <br/> -->
<!-- ## 54. Jak testujemy efekty losowe w modelu mieszanym? -->
<!-- <br/> -->
<!-- ## 55. Czym jest i do czego służy model z powtarzanymi pomiarami? -->
</section>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>